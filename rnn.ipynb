{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6342ca3",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da370ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02e0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./IMDB-Dataset.csv\", names=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f425a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                     text      label\n",
       "0                                                 review  sentiment\n",
       "1      One of the other reviewers has mentioned that ...   positive\n",
       "2      A wonderful little production. <br /><br />The...   positive\n",
       "3      I thought this was a wonderful way to spend ti...   positive\n",
       "4      Basically there's a family where a little boy ...   negative\n",
       "...                                                  ...        ...\n",
       "49996  I thought this movie did a down right good job...   positive\n",
       "49997  Bad plot, bad dialogue, bad acting, idiotic di...   negative\n",
       "49998  I am a Catholic taught in parochial elementary...   negative\n",
       "49999  I'm going to have to disagree with the previou...   negative\n",
       "50000  No one expects the Star Trek movies to be high...   negative\n",
       "\n",
       "[50001 rows x 2 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69176994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50001, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b85e1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da571ff",
   "metadata": {},
   "source": [
    "# Add words in to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e235d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"UNK\": 2, \"PAD\": 3}\n",
    "        self.word2count = {\"SOS\":0, \"EOS\": 0}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3: \"PAD\"}\n",
    "        self.n_words = 4 \n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        sentence = str(sentence)\n",
    "\n",
    "        for word in sentence.split():\n",
    "            self.addWord(word)\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3616ad89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = Lang()\n",
    "df['text'].apply(lambda row: (lang.addSentence(row)))\n",
    "lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb2f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].astype(str).str.strip().map({\"positive\": 1, \"negative\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d57a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        1.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        0.0\n",
       "        ... \n",
       "49996    1.0\n",
       "49997    0.0\n",
       "49998    0.0\n",
       "49999    0.0\n",
       "50000    0.0\n",
       "Name: label, Length: 50001, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a5595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"text\"].str.len() < 2000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f6a06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41576</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41577</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41578</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41579</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41580</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41581 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0                                                 review    NaN\n",
       "1      One of the other reviewers has mentioned that ...    1.0\n",
       "2      A wonderful little production. <br /><br />The...    1.0\n",
       "3      I thought this was a wonderful way to spend ti...    1.0\n",
       "4      Basically there's a family where a little boy ...    0.0\n",
       "...                                                  ...    ...\n",
       "41576  I thought this movie did a down right good job...    1.0\n",
       "41577  Bad plot, bad dialogue, bad acting, idiotic di...    0.0\n",
       "41578  I am a Catholic taught in parochial elementary...    0.0\n",
       "41579  I'm going to have to disagree with the previou...    0.0\n",
       "41580  No one expects the Star Trek movies to be high...    0.0\n",
       "\n",
       "[41581 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39316d",
   "metadata": {},
   "source": [
    "# Turn sentences to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "625768cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5da8bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, lang, print):\n",
    "        self.df = df\n",
    "        self.lang = lang\n",
    "        self.print = print\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        #build pairs\n",
    "        row = self.df.iloc[idx]\n",
    "        input_tensor = self.tensorFromSentence(row['text'])\n",
    "        return input_tensor, row['label']\n",
    "\n",
    "    def indexesFromSentence(self, sentence):\n",
    "        \n",
    "        #turn sentence into word indexes\n",
    "        sentence = str(sentence)\n",
    "        words = sentence.split()\n",
    "        indexes = [self.lang.word2index.get(w, self.lang.word2index['UNK']) for w in words]\n",
    "        return indexes\n",
    "\n",
    "    def tensorFromSentence(self, sentence):\n",
    "\n",
    "        if self.print:\n",
    "            print(sentence)\n",
    "\n",
    "        #add a eos to the end of sentence\n",
    "        indexes = []\n",
    "        indexes.append(self.lang.word2index['SOS'])\n",
    "        indexes+=(self.indexesFromSentence(sentence))\n",
    "        indexes.append(self.lang.word2index['EOS'])\n",
    "        return torch.tensor(indexes, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b03b8e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am barton\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([     0, 146490,    156,   1898,      2,      1], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = TranslationDataset(df, lang, print=True)\n",
    "translation.tensorFromSentence(\"Hello, I am barton\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5a64b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "        inputs, targets = zip(*batch)\n",
    "        lengths = torch.tensor([len(x) for x in inputs], dtype=torch.long)\n",
    "\n",
    "        inputs_padded = pad_sequence(inputs, padding_value=lang.word2index['PAD'],batch_first=True)\n",
    "        targets = torch.tensor(targets, dtype=torch.float)\n",
    "        return inputs_padded, targets, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0f074",
   "metadata": {},
   "source": [
    "# Load and split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec7b5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = TensorDataset(df['text'],df['label'])\n",
    "train_text = df.sample(frac = 0.8)\n",
    "test_test = df.drop(train_text.index)\n",
    "train, test = TranslationDataset(train_text, lang, print=False), TranslationDataset(test_test, lang, print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33816b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            num_workers=0,\n",
    "                            collate_fn=collate_fn,drop_last=True)\n",
    "test_dataloader = DataLoader(test, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            num_workers=0  ,\n",
    "                            collate_fn=collate_fn,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "babc5ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,     64,    398,  ...,      3,      3,      3],\n",
      "        [     0,    155,    137,  ...,      3,      3,      3],\n",
      "        [     0,   4666,    327,  ...,      3,      3,      3],\n",
      "        ...,\n",
      "        [     0,    156,    412,  ...,      3,      3,      3],\n",
      "        [     0,   1177,  36666,  ...,      3,      3,      3],\n",
      "        [     0,     94, 379472,  ...,      3,      3,      3]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "one_x, one_y, length= next(iter(train_dataloader))\n",
    "print(one_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeeabd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 128\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(lang.n_words, embedding_dim, padding_idx=lang.word2index['PAD'])\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        #x(L, N)\n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        #out(N, L, Embedding_dim)\n",
    "        out = self.embedding(x)\n",
    "\n",
    "        #hx(num_layer, N, hidden_size)\n",
    "        #hx = torch.zeros(1, x.size(0), hidden_size,device=device) \n",
    "        \n",
    "        #out(L, N, hidden_size)\n",
    "        #hx(num_layer, N, hidden_size)\n",
    "\n",
    "        out = pack_padded_sequence(out, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        out, hx = self.rnn(out)\n",
    "\n",
    "        #out(L, N)\n",
    "        out = self.linear(hx[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b7652f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402421f4",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da58300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epoch):\n",
    "    losses = []\n",
    "    n = len(train_dataloader)\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for input, output, lengths in train_dataloader:\n",
    "            output = output.type(dtype=torch.long)\n",
    "            input, output, lengths = input.to(device), output.to(device), lengths.to(device)\n",
    "            pred_y = model(input, lengths)\n",
    "            loss = criterion(pred_y, output)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        losses.append(epoch_loss / n)\n",
    "        print(f\"epoch {epoch}, loss {epoch_loss / n:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, n_epoch + 1), losses, marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9342e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "813330ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"RNN.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8308d",
   "metadata": {},
   "source": [
    "if you have trained model, you can remark train and load it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = MLP().to(device)\n",
    "#model.load_state_dict(torch.load(\"RNN.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063a120",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.2770\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "n = len(test_dataloader)\n",
    "losses = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for input, output, lengths in test_dataloader:\n",
    "        output = output.type(dtype=torch.long)\n",
    "        input, output, lengths = input.to(device), output.to(device), lengths.to(device)\n",
    "        pred_y = model(input, lengths)\n",
    "        loss = criterion(pred_y, output)\n",
    "        epoch_loss += loss.item()\n",
    "    losses.append(epoch_loss / n)\n",
    "    print(f\"loss {epoch_loss / n:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
